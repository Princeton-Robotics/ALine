{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV/Python Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by installing opencv and dlib with pip/pip3:\n",
    "# pip3 install opencv-python\n",
    "# pip3 install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing opencv, numpy, an dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "from math import atan2\n",
    "from math import pi as PI\n",
    "\n",
    "SHOW_FACE_POINTS = False\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/Kyle/Downloads/shape_predictor_68_face_landmarks.dat') # Replace with your path, \n",
    "                    # download here: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2, extract\n",
    "moustache_mask = 1-(cv2.imread('C:/Users/Kyle/Desktop/mous.jfif')/255) # convert to mask, https://www.bing.com/th?id=OIP.ftDeHYROqGLXXU2IH3xg7wHaCd&pid=Api&rs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Between Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will convert an image to greyscale by first converting it to the HSV\n",
    "# colorspace, from BGR, then taking the Luminance Channel.\n",
    "def ConvertToBW(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    grey = hsv[:,:,2]\n",
    "    return grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will blur the image by average neighboring values\n",
    "def BlurImage(image):\n",
    "    kernel = np.array([[1,1,1,1,1],\n",
    "                      [1,1,1,1,1],\n",
    "                      [1,1,1,1,1],\n",
    "                      [1,1,1,1,1],\n",
    "                      [1,1,1,1,1]])\n",
    "    kernel = kernel / 25\n",
    "    blurred = cv2.filter2D(image, -1, kernel) # -1 keeps depth/percision the same\n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will find edges in an image, using the Sobel operator/kernel\n",
    "def DetectEdges(image):\n",
    "    image = image.astype(np.float32)\n",
    "    vertical_edge_kernel = np.array([[-1, 0, 1],\n",
    "                                    [-2, 0, 2],\n",
    "                                    [-1, 0, 1]])\n",
    "    horizontal_edge_kernel = np.array([[-1, -2, -1],\n",
    "                                       [0, 0, 0],\n",
    "                                       [1, 2, 1]])\n",
    "    vertical_edges = cv2.filter2D(image, -1, vertical_edge_kernel)\n",
    "    horizontal_edges = cv2.filter2D(image, -1, horizontal_edge_kernel)\n",
    "    summed = (vertical_edges ** 2) + (horizontal_edges ** 2)\n",
    "    edges = summed ** 0.5\n",
    "    edges[edges < 125] = 0 # can adjust threshold\n",
    "    edges[edges >= 125] = 255\n",
    "    return edges.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function looks for a face\n",
    "def Moustache(image):\n",
    "    grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # OpenCV has a lot of color spaces, not just hsv\n",
    "    rects = detector(grey, 1) # get bounding boxes of faces\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(grey, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\n",
    "        if SHOW_FACE_POINTS:\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # show the face number\n",
    "            cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # loop over the (x, y)-coordinates for the facial landmarks\n",
    "            # and draw them on the image\n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "                \n",
    "        # draw mustache\n",
    "        nose_avg = np.average(shape[32:37], axis=0) # Slices exclusive, see https://www.pyimagesearch.com/wp-content/uploads/2017/04/facial_landmarks_68markup-768x619.jpg\n",
    "        top_lip_avg = np.average(shape[51:54], axis=0)\n",
    "        mous = imutils.resize(moustache_mask, width=int(w/3))\n",
    "        \n",
    "        # Calculate position\n",
    "        (avg_y,avg_x) = (nose_avg + top_lip_avg)/2\n",
    "        avg_x = int(avg_x)\n",
    "        avg_y = int(avg_y)\n",
    "        \n",
    "        # Calculate rotation, using corners of mouth\n",
    "        (left_x, left_y) = shape[54]\n",
    "        (right_x, right_y) = shape[48]\n",
    "        deltaY = left_y - right_y\n",
    "        deltaX = left_x - right_x\n",
    "        angleInDegrees = atan2(deltaY, deltaX) * 180 / PI\n",
    "        mous = 1-imutils.rotate_bound(mous, angleInDegrees)\n",
    "        \n",
    "        lower_x = max(avg_x - int(mous.shape[0]/2), 0)\n",
    "        higher_x = min(avg_x + int(mous.shape[0]/2), image.shape[0])\n",
    "        lower_y = max(avg_y - int(mous.shape[1]/2), 1)\n",
    "        higher_y = min(avg_y + int(mous.shape[1]/2), image.shape[1])\n",
    "        #print(mous.shape)\n",
    "        if (mous.shape[0] != higher_x - lower_x):\n",
    "            higher_x = higher_x + mous.shape[0] - (higher_x - lower_x)\n",
    "        if (mous.shape[1] != higher_y - lower_y):\n",
    "            higher_y = higher_y + mous.shape[1] - (higher_y - lower_y)\n",
    "        image[lower_x:higher_x, lower_y:higher_y, :] = mous * image[lower_x:higher_x, lower_y:higher_y, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object, pass 0 to read from (first) camera on system\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = imutils.resize(frame, width=300)\n",
    "    \n",
    "    if ret == True:\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('input',frame)\n",
    "        cv2.imshow('BW',ConvertToBW(frame))\n",
    "        cv2.imshow('Blur',BlurImage(frame))\n",
    "        cv2.imshow('Edge',DetectEdges(frame))\n",
    "        cv2.imshow('Moustache',Moustache(frame))\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'): #25ms pause between each frame\n",
    "            break\n",
    "\n",
    "    # Break the loop\n",
    "    else: \n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
